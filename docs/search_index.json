[["index.html", "Introduction to Environmental Data Science: Final Project Preface References", " Introduction to Environmental Data Science: Final Project Amanda Hastings 2022-03-25 Preface This book contains six different projects completed in ESS580: Introduction to Environmental Data Science taught by Dr. Matt Ross and Dr. Nathan Mueller at Colorado State University. Each chapter details the purpose, data acquisition, analyses (where applicable), and results of an individual project completed in the 2022 spring semester. For each project, Dr. Matt Ross and/or Dr. Nathan Mueller wrote the preliminary code and outlined project objectives. I completed the remaining portions of each project and compiled this book. References R packages used consistently throughout this book include: Appelhans et al. (2021). mapview-package: Interactive viewing of spatial objects in R. R package version 2.10.0. https://github.com/r-spatial/mapview Arnold, JB. (2021). ggthemes: Extra Themes, Scales and Geoms for ggplot2. R package version 4.2.4. https://CRAN.R-project.org/package=ggthemes Grolemund, G. and Wickham, H. (2011). Dates and Times Made Easy with lubridate. Journal of Statistical Software, 40(3), 1-25. URL https://www.jstatsoft.org/v40/i03/. Mullen, LA. and Bratt, B. (2018). USAboundaries: Historical and Contemporary Boundaries of the United States of America, Journal of Open Source Software, 3(23), 314. https://doi.org/10.21105/joss.00314. Pebesma, E. (2018). Simple Features for R: Standardized Support for Spatial Vector Data. The R Journal 10(1), 439-446. https://doi.org/10.32614/RJ-2018-009 Robinson, D., Hayes, A., and Couch, S. (2022). broom: Convert Statistical Objects into Tidy Tibbles. R package version 0.7.11. https://CRAN.R-project.org/package=broom Ryan, JA. and Ulrich, JM. (2020). xts: eXtensible Time Series. R package version 0.12.1. https://CRAN.R-project.org/package=xts Vanderkam, D., Allaire, JJ., Owen, J., Gromer, D., and Thieurmel, B. (2018). dygraphs: Interface to Dygraphs Interactive Time Series Charting Library. R package version 1.1.1.6. https://CRAN.R-project.org/package=dygraphs Wickham et al. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686 "],["workflow-tools.html", "Chapter 1 Workflow Tools 1.1 Introduction 1.2 Methods 1.3 Results 1.4 Poudre River Information 1.5 References", " Chapter 1 Workflow Tools 1.1 Introduction This project served as an introduction to workflow tools: R Markdown, Git, and GitHub. To complete project objectives, we utilized US Geological Survey (USGS) discharge data for the Cache la Poudre River at the Lincoln Avenue bridge in Fort Collins, CO. Project objectives included: Fork example repository to personal GitHub Explore R Markdown formatting Utilize dygraphs package for interactive plotting Commit and push work to GitHub 1.2 Methods Site Description The Poudre River at Lincoln Bridge is: Near Old Town Fort Collins, CO and multiple craft breweries, including Odell Brewing Near an open space and the Poudre River Trail Downstream of only some urban stormwater Downstream of many agricultural diversions Figure 1. The Lincoln Avenue bridge was reconstructed in 2017 to accommodate sidewalks and bike lanes. Photograph courtesy of Otak. Figure 2. USGS Station at the Lincoln Bridge location, Poudre River - Fort Collins, CO. Photograph courtesy of USGS. Data Acquistion We retrieved discharge data using the dataRetrieval R package from the USGS NWIS web service. #Download Poudre River discharge data at Lincoln Bridge site from NWIS web service DischargeData &lt;- readNWISdv( siteNumbers = &#39;06752260&#39;, parameterCd = &#39;00060&#39;, startDate = &#39;2017-01-01&#39;, endDate = &#39;2022-01-01&#39;) %&gt;% rename(discharge = &#39;X_00060_00003&#39;) 1.3 Results Static Plotting Figure 3. Static plot using the ggplot (tidyverse) package in R to visualize discharge in the Poudre River, Fort Collins, CO. Interactive Plotting Figure 4. Interactive plot of discharge in the Poudre River using the dygraphs package in R. 1.4 Poudre River Information Figure 5. Cache la Poudre River. Photograph courtesy of Marek Uliasz. Meandering through Roosevelt National Forest and dropping approximately 7,000 feet in elevation, the Cache la Poudre River stretches from peaks along the Continental Divide to foothills of the Front Range near Fort Collins, CO (USFS). Despite the great length of the river, stretches of uninterrupted habitat for resident fishes are becoming increasingly limited particularly with the construction of man-made diversion structures (Bloom, 2018). As of 2018, researchers estimated approximately 82% Great Plains fish are in decline, with species such as the common shiner, Luxilus cornutus, and the central stoneroller, Campostoma anomalum, potentially lost to northern Colorado waterways (Bloom, 2018). Species including small minnows such as the red shiner, Cyprinella lutrensis, and orangespotted sunfish, Lepomis humilis require stretches of at least 30 miles to migrate and spawn (Bloom, 2018). However, could another man-made structure potentially offset the necessary, yet imperiling, structures in place? CSU researcher Dr. Chris Myrick and his graduate students built a fish ladder for small fishes, similar to those previously built for larger fishes, to essentially extend their, otherwise interrupted, habitat. Here is a fish eyes view of the fish ladder the team created. While the only fish ladder within Larimer County, the research team hopes the design will be transferable and a means to protect small fish across other states as well (Bloom, 2018). Another noteworthy fact about the Poudre river: it is the only designated National Wild and Scenic River within the state of Colorado (USFS). A map of the National Wild and Scenic Rivers system can be found here. Presentation link This chapter has also been formatted into a presentation/talk using the reveal.js package. The formatted version can be found here. 1.5 References Bloom, Matt.(2018, March) To Reverse The Disappearance of Native Fish, North Colorado Is Turning to Fish Ladders. NPR for Northern Colorado. kunc.org Interagency Wild &amp; Scenic Rivers Council. MAPS &amp; GIS. National Wild and Scenic Rivers System. rivers.gov/mapping-gis.php. Accessed January 26, 2022. Otak (2017). Lincoln Avenue Bridge,Our Project, Otak. otak.com Uliasz, Marek.(2019, August) Cache la Poudre River, Colorados Scenic and Historic Byways: Cache La Poudre/North Park, 5280 Denvers Mile High Magazine, 5280.com USDA Forest Service (USFS). Cache la Poudre Wild and Scenic River. fs.usda.gov. Accessed January 26, 2022. Data Retrieval R Packages De Cicco, LA., Hirsch, RM., Lorenz, D., Watkins, WD., and Johnson, M. (2022). dataRetrieval: R packages for discovering and retrieving water data available from federal hydrologic web services. https://code.usgs.gov/water/dataRetrieval. "],["data-wrangling.html", "Chapter 2 Data Wrangling 2.1 Introduction 2.2 Methods 2.3 Results 2.4 References", " Chapter 2 Data Wrangling 2.1 Introduction This project served as an introduction and exploration in data munging. We retrieved data using the Climate Engine app to investigate vegetation recovery following the 2002 Hayman Fire in Colorado. We specifically looked at normalized difference vegetation index (NDVI), normalized difference snow index (NDSI), and normalized difference moisture index (NDMI), between unburned and burned sites and before and after the fire event. Once manipulating the data, we performed basic analyses to address the following project questions: What is the correlation between NDVI and NDMI? What is the correlation between average NDSI for winter months: January - April and average NDVI for summer months: June-August? How does snow cover from the previous year influence vegetation growth in the following summer? How does the correlation in snow cover and vegetation growth (from question b) vary between burned and unburned sites and pre- and post-fire time periods? 2.2 Methods Data Acquistion #Read in files and store in data folder files &lt;- list.files(&#39;dataDataWrangle&#39;,full.names=T) #Read in individual data files separately #NDMI data ndmi &lt;- read_csv(files[1]) %&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndmi&#39;) #NDSI data ndsi &lt;- read_csv(files[2]) %&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndsi&#39;) #NDVI data ndvi &lt;- read_csv(files[3])%&gt;% rename(burned=2,unburned=3) %&gt;% mutate(data=&#39;ndvi&#39;) # Stack data as a tidy dataset full_long &lt;- rbind(ndvi,ndmi,ndsi) %&gt;% gather(key=&#39;site&#39;,value=&#39;value&#39;,-DateTime,-data) %&gt;% filter(!is.na(value)) 2.3 Results Question A: NDVI and NDMI #Convert from long to wide data with spread() #Add month and year columns to wide data full_wide1 &lt;- full_long %&gt;% spread(key=&#39;data&#39;, value=&#39;value&#39;) %&gt;% mutate(month=month(DateTime)) %&gt;% mutate(year=year(DateTime)) #Limit data to only summer months using filter() summer_wide &lt;- full_wide1 %&gt;% filter(month %in% c(6,7,8)) #Plot ndvi as response and ndmi as predictor #Distinguish between burn or unburned sites ggplot(summer_wide, aes(x=ndmi, y=ndvi, color=site))+ geom_point(alpha=0.25)+ labs(x=&quot;NDMI&quot;, y=&quot;NDVI&quot;)+ theme_few()+ scale_color_manual(name=&quot;Site&quot;,labels=c(&quot;Burned&quot;,&quot;Unburned&quot;), values= c(&quot;#274a12&quot;,&quot;#babf28&quot;))+ xlim(-0.6,0.7)+ ylim(0.05, 0.6) # Plot ndvi vs ndmi with facet wrap over site type (burned or unburned) ggplot(summer_wide, aes(x=ndmi, y=ndvi))+ geom_point(alpha=0.25)+ labs(x=&quot;NDMI&quot;, y=&quot;NDVI&quot;)+ theme_few()+ facet_wrap(&#39;site&#39;, labeller = labeller(site = Site)) Figures 1-2. NDMI and NDVI spanning summer months in burned versus unburned sites in the Hayman fire area. #Test correlation between ndvi and ndmi cor.test(summer_wide$ndmi, summer_wide$ndvi, method=&#39;pearson&#39;) #Fit lm model for ndvi by ndmi LMFit1 &lt;- lm(ndvi~ndmi, data =summer_wide) summary(LMFit1) Based upon a test of correlation, we have evidence of a positive linear association between summer NDMI and summer NDVI, with a p-value &lt; 2.2e-16 (less than 0.05). For every 1 unit increase in summer NDMI, there is a 0.908772 increase in summer NDVI (p-value &lt; 2.2e-16). Question B: Winter NDSI and Summer NDVI #Summarize data by average ndvi for summer months summer_ndvi&lt;- full_wide1 %&gt;% group_by(site, year, month) %&gt;% filter(month %in% c(6, 7, 8)) %&gt;% summarize(mean_ndvi = mean(ndvi)) %&gt;% filter(!is.na(mean_ndvi)) #Summarize data by average ndsi over winter months winter_ndsi &lt;- full_wide1 %&gt;% group_by(site, year, month) %&gt;% filter(month %in% c(1, 2, 3, 4)) %&gt;% summarize(mean_ndsi = mean(ndsi)) %&gt;% filter(!is.na(mean_ndsi)) #Join average summer ndvi and average winter ndsi by year and site #Add burnperiod column to distinguish pre- and post-fire years wide_averages &lt;- inner_join(winter_ndsi, summer_ndvi, by= c(&#39;site&#39;, &#39;year&#39;)) %&gt;% mutate(burnperiod = as.factor(ifelse(year &lt; 2002,&quot;prefire&quot;, &quot;postfire&quot;))) #Plot and evaluate relationship between ndvi and ndsi ggplot(wide_averages, aes(x=mean_ndsi, y=mean_ndvi))+ geom_point(alpha=.5, color = &quot;#22AA99&quot;)+ geom_smooth(method=lm, color=&quot;#22AA99&quot;, size=0.1, se=FALSE)+ theme_few()+ labs(x=&quot;Average Winter NDSI&quot;, y=&quot;Average Summer NDVI&quot;) Figure 3. Average winter NDSI and average summer NDVI across all sites over time. #Test correlation between ndvi and ndsi overall cor.test(wide_averages$mean_ndsi, wide_averages$mean_ndvi) #Fit lm model for ndvi by ndsi overall LMFit2 &lt;- lm(mean_ndvi~mean_ndsi, data = wide_averages) summary(LMFit2) The p-value from a test of correlation for average summer NDVI and average winter NDSI is 0.0002124 and less than 0.05. We have evidence of a positive linear association between average summer NDVI and average winter NDSI. For every 1 unit increase in average winter NDSI, there is a 0.042658 increase in average summer NDVI. Question C: NDVI-NDSI correlations NDVI-NDSI: Pre- versus post-fire figure and analyses #Plot and compare ndvi-ndsi relationship between pre- and post-burn periods ggplot(wide_averages, aes(x=mean_ndsi, y=mean_ndvi, color=burnperiod))+ geom_point(alpha=0.5)+ theme_few()+ geom_smooth(method=lm, size=0.1, se=FALSE)+ labs(x=&quot;Average Winter NDSI&quot;, y=&quot;Average Summer NDVI&quot;)+ scale_color_manual(name=&quot;&quot;,labels=c(&quot;Pre-fire&quot;,&quot;Post-fire&quot;), values= c(&quot;#2f94b5&quot;,&quot;#b5982f&quot;)) Figure 4. Average winter NDSI and average summer NDVI in pre- and post-fire years. #Fit lm model to evaluate ndvi-ndsi correlation pre- and post-fire LMFit3 &lt;- lm(mean_ndvi~mean_ndsi*burnperiod, data= wide_averages) summary(LMFit3) #Create separate data frames for prefire and postfire prefire &lt;- wide_averages %&gt;% filter(burnperiod %in% &#39;prefire&#39;) postfire &lt;- wide_averages %&gt;% filter(burnperiod %in% &#39;postfire&#39;) #Test correlation between ndvi and ndsi prefire and postfire cor.test(prefire$mean_ndsi,prefire$mean_ndvi) cor.test(postfire$mean_ndsi,postfire$mean_ndvi) In pre-fire years, we do not have evidence of an association between average summer NDVI and average winter NDSI (p-value=0.1721). However, in post-fire years, we have evidence of an association between average summer NDVI and average winter NDSI (p-value=0.01048). NDVI-NDSI: Burned versus unburned figure and analyses #Plot and compare ndvi-ndsi relationship across burned versus unburned sites ggplot(wide_averages, aes(x=mean_ndsi, y=mean_ndvi, color=site))+ geom_point(alpha=0.5)+ theme_few()+ geom_smooth(method=lm, size=0.1, se=FALSE)+ labs(x=&quot;Average Winter NDSI&quot;, y=&quot;Average Summer NDVI&quot;)+ scale_color_manual(name=&quot;Site&quot;,labels=c(&quot;Burned&quot;,&quot;Unburned&quot;), values= c(&quot;#292423&quot;,&quot;#a4a823&quot;)) Figure 5. Average winter NDSI and average summer NDVI between burned and unburned sites. #Fit lm model to evaluate ndvi-ndsi correlation between burned and unburned sites LMFit4 &lt;- lm(mean_ndvi~mean_ndsi*site, data=wide_averages) summary(LMFit4) #Create separate data frames for burned and unburned sites burned &lt;- wide_averages %&gt;% # filter(burnperiod %in% &#39;postfire&#39;) %&gt;% filter(site %in% &#39;burned&#39;) unburned &lt;- wide_averages %&gt;% # filter(burnperiod %in% &#39;postfire&#39;) %&gt;% filter(site %in% &#39;unburned&#39;) #Test correlation between ndvi and ndsi in burned and unburned sites separately cor.test(burned$mean_ndsi, burned$mean_ndvi) cor.test(unburned$mean_ndsi,unburned$mean_ndvi) When analyzing all years included in the dataset, we do not have evidence of an association between average summer NDVI and average winter NDSI within the unburned area (p-value= 0.6589) and burned area (p-value=0.1825). When analyzing only years postfire, we still do not have evidence of an association between average summer NDVI and average winter NDSI in the unburned (p-value=0.905) and burned areas (p-value=0.3226). Additional findings Lastly, when looking at overall trends in NDVI and NDSI, we found August is the greenest month on average while February is the snowiest month on average. 2.4 References Climate Engine. (2022). Desert Research Institute and University of Idaho. Accessed February 7,2022. http://climateengine.org. Huntington, J., Hegewisch, K., Daudert, B., Morton, C., Abatzoglou, J., McEvoy, D., and Erickson, T. (2017). Climate Engine: Cloud Computing of Climate and Remote Sensing Data for Advanced Natural Resource Monitoring and Process Understanding. Bulletin of the American Meteorological Society, http://journals.ametsoc.org/doi/abs/10.1175/BAMS-D-15-00324.1 "],["key-programming-concepts.html", "Chapter 3 Key Programming Concepts 3.1 Introduction 3.2 Data Acquisiton: Snowpack Depth 3.3 Results: Snowpack Depth 3.4 Data Acquisition: Meterological Data 3.5 Results: Meterological Data 3.6 References", " Chapter 3 Key Programming Concepts 3.1 Introduction This project served as an introduction to webscraping, iteration, and functions. We extracted data from the Center for Snow and Avalanche Studies (CSAS) website: home to incredibly rich snow, temperature, and precipitation data. Project objectives: Extract data URLS or CSV links from website Download data using a for loop or map function Write custom functions 3.2 Data Acquisiton: Snowpack Depth Webscraping: extract links from webpage #Save site URL site_url &lt;- &#39;https://snowstudies.org/archived-data/&#39; #Read the web URL webpage &lt;- read_html(site_url) #Extract only weblinks and then URLs links &lt;- webpage %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;24hr&#39;,.)] %&gt;% html_attr(&#39;href&#39;) Download data using a for loop #Split by forward slashes to parse out name of file splits &lt;- str_split_fixed(links,&#39;/&#39;,8) #Select column containing file name dataset &lt;- splits[,8] #Generate a file list to hold the data file_names &lt;- paste0(&#39;dataFunctions/&#39;,dataset) #Download data in a for loop for(i in 1:3){ download.file(links[i],destfile=file_names[i]) } downloaded &lt;- file.exists(file_names) evaluate &lt;- !all(downloaded) Download data using map function(s) #Utilize map for same operation as above, download the same 3 files if(evaluate == T) { map2(links[1:3], file_names[1:3], download.file) } else{ print(&#39;data already downloaded&#39;) } Read in snow data with pattern matching and a for loop #Use pattern matching to only keep certain files snow_files &lt;- file_names %&gt;% .[!grepl(&#39;SG_24&#39;,.)] %&gt;% .[!grepl(&#39;PTSP&#39;,.)] #Read in only snow data as a loop #empty_data &lt;- list() # snow_data &lt;- for(i in 1:length(snow_files)){ # empty_data[[i]] &lt;- read_csv(snow_files[i]) %&gt;% # select(Year,DOY,Sno_Height_M) # } #snow_data_full &lt;- do.call(&#39;rbind&#39;,empty_data) Read in snow data with map function #Create function to read in snow files our_snow_reader &lt;- function(file){ name = str_split_fixed(file,&#39;/&#39;,2)[,2] %&gt;% gsub(&#39;_24hr.csv&#39;,&#39;&#39;,.) df &lt;- read_csv(file) %&gt;% select(Year,DOY,Sno_Height_M) %&gt;% mutate(site = name) } snow_data_full &lt;- map_dfr(snow_files,our_snow_reader) 3.3 Results: Snowpack Depth #Create column for yearly mean snow height by site snow_yearly &lt;- snow_data_full %&gt;% group_by(Year,site) %&gt;% summarize(mean_height = mean(Sno_Height_M,na.rm=T)) #Plot yearly mean snow height by site ggplot(snow_yearly,aes(x=Year,y=mean_height,color=site)) + geom_point(alpha=0.75, size=2) + ggthemes::theme_few() + scale_color_manual(name=&quot;Study Plots&quot;, labels=c(&quot;Swamp Angel&quot;,&quot;Senator Beck&quot;), values= c(&quot;#58A3EB&quot;,&quot;#58E8EB&quot;))+ labs(y=&quot;Depth of Snowpack (m)&quot;,title=&quot;Average Snow Height over Time&quot;) Figure 1. Yearly snow pack depth for Swamp Angel and Senator Beck study plots, Center for Snow and Avalanche Studies. Height of snow was sampled once at the end of an array. 3.4 Data Acquisition: Meterological Data Webscraping: extract meterological data URLs #Extract data URLs for SASP forcing and SBSP forcing datasets site_url2 &lt;- &#39;https://snowstudies.org/archived-data/&#39; webpage2 &lt;- read_html(site_url2) links2 &lt;- webpage2 %&gt;% html_nodes(&#39;a&#39;) %&gt;% .[grepl(&#39;forcing&#39;,.)] %&gt;% html_attr(&#39;href&#39;) Download meteorological data #Download the meterological data and save within data folder splits2 &lt;- str_split_fixed(links2,&#39;/&#39;,8) dataset2 &lt;- splits2[,8] filenames2 &lt;- paste0(&#39;dataFunctions/&#39;,dataset2) #Utilize map2() to download data map2(links2,filenames2,download.file) Write a custom function to read in data #Retrieve variable names from the metadata pdf file headers &lt;- pdf_text(&#39;https://snowstudies.org/wp-content/uploads/2022/02/Serially-Complete-Metadata-text08.pdf&#39;) %&gt;% readr::read_lines(.) %&gt;% trimws(.) %&gt;% str_split_fixed(.,&#39;\\\\.&#39;,2) %&gt;% .[,2] %&gt;% .[1:26] %&gt;% str_trim(side = &quot;left&quot;) #Write a function to read in the data and append site column forcing_files &lt;- filenames2 file &lt;- forcing_files[1] forcefile_reader &lt;- function(file) { name2 = str_split_fixed(file, &#39;_&#39;, 3)[, 2] df &lt;- read.csv(file, header = FALSE, sep = &#39;&#39;) %&gt;% select(V1, V2, V3, V7, V10) %&gt;% rename( year = 1, month = 2, day = 3, precip = 4, airtemp = 5 ) %&gt;% mutate(site = name2) } Read in meterological data files with map function #Use map function to read in meteorological files forcing_data_full &lt;- map_dfr(forcing_files, forcefile_reader) #Display summary as tibble forcing_tibble &lt;-as_tibble(forcing_data_full) knitr::kable(head(forcing_tibble)) year month day precip airtemp site 2003 11 10 0.0000000 270.135 SASP 2003 11 10 0.0002778 269.923 SASP 2003 11 10 0.0002778 269.707 SASP 2003 11 10 0.0002778 269.552 SASP 2003 11 10 0.0008333 269.467 SASP 2003 11 10 0.0002778 269.392 SASP 3.5 Results: Meterological Data #Create data frame with mean air temperature by year by site temp_yearly &lt;- forcing_data_full %&gt;% filter(!year %in% 2003) %&gt;% group_by(year,site) %&gt;% summarize(mean_yrtemp = mean(airtemp, na.rm=T)) #Make line plot of mean temperature by year by site ggplot(temp_yearly, aes(x=year, y=mean_yrtemp, color=site))+ geom_line(size=.75)+ theme_few()+ scale_color_manual(name=&quot;Study Plots&quot;, labels=c(&quot;Swamp Angel&quot;,&quot;Senator Beck&quot;), values= c(&quot;#58A3EB&quot;,&quot;#58E8EB&quot;))+ labs(x=&#39;Year&#39;, y=&#39;Average Air Temperature (K)&#39;) Figure 2. Yearly mean air temperature for Swamp Angel and Senator Beck study plots, CSAS. Records from 2003 were excluded given data was only available for two months out of the year. #Write function to make line plots of monthly average temps per site per year line_plotter &lt;- function(df, year) { temp_monthly &lt;- df %&gt;% group_by(year, month, site) %&gt;% summarize(mean_motemp = mean(airtemp, na.rm = T)) %&gt;% filter(i == year) print( ggplot(temp_monthly, aes( x = month, y = mean_motemp, color = site )) + geom_line(size = .75) + theme_few() + scale_color_manual(name=&quot;Study Plots&quot;, labels=c(&quot;Swamp Angel&quot;,&quot;Senator Beck&quot;), values = c(&quot;#762448&quot;, &quot;#B1D374&quot;)) + labs(x=&quot;Month&quot;,y = &#39;Average Air Temperature (K)&#39;, title = i)+ scale_x_continuous( breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), labels = c(&#39;January&#39;,&#39;February&#39;,&#39;March&#39;,&#39;April&#39;,&#39;May&#39;,&#39;June&#39;,&#39;July&#39;,&#39;August&#39;,&#39;September&#39;,&#39;October&#39;,&#39;November&#39;,&#39;December&#39;)) + theme( axis.text.x = element_text( color = &quot;black&quot;, size = 8, angle = 30, vjust = .8, hjust = .8 ) )) } #Use for loop to plot years 2005 to 2010 yrs = c(2005:2010) for (i in yrs){ line_plotter(forcing_data_full,year) } Figures 3-8. Monthly average temperature at study plots: Swamp Angel and Senator Beck, years 2005-2010. #Add date column to data frame #Use lubridate:: yday for day of year precip_daily &lt;- forcing_data_full %&gt;% group_by(month, day, year, site) %&gt;% summarize(mean_precip = mean(precip, na.rm = T)) %&gt;% mutate(date = as.Date(paste(year, month, day, sep = &quot;/&quot;))) %&gt;% mutate(yday = yday(date)) %&gt;% pivot_wider(names_from = site, values_from = mean_precip) %&gt;% dplyr::select(-SBSP)%&gt;% group_by(yday)%&gt;% summarize(mean_dy_precip = mean(SASP)) #Create plot with mean daily precip by day of year using ggplot ggplot(precip_daily, aes(x = yday, y = mean_dy_precip)) + geom_point(alpha=0.5) + theme_few() + labs(x = &#39;Day of Year&#39;, y = expression(&#39;Average Precipitation&#39; ~ (&#39;kg&#39; * m ^ 2 * &#39; per day&#39;)))+ scale_x_continuous(breaks=c(1,90,180,270,360)) Figure 9. Average daily precipitation by day of year at the Swamp Angel study plot, averaged across available years. #Create plot with mean daily precip by day of year using dygraphs #This is not averaged across available years precip_daily2 &lt;- forcing_data_full %&gt;% group_by(month, day, year, site) %&gt;% summarize(mean_precip = mean(precip, na.rm = T)) %&gt;% mutate(date = as.Date(paste(year, month, day, sep = &quot;/&quot;))) %&gt;% pivot_wider(names_from = site, values_from = mean_precip) %&gt;% ungroup() %&gt;% select(-SBSP, -month, -day, -year) precip_xts2 &lt;- xts(precip_daily2 %&gt;% select(SASP), order.by = precip_daily2$date) dygraph(precip_xts2, ylab = &quot;&quot;) %&gt;% dyOptions(fillGraph = TRUE, axisLabelFontSize=12) %&gt;% dySeries(&quot;SASP&quot;, label = &quot;Average Daily Precipitation (kgm2 per day)&quot;)%&gt;% dyLegend(width=400,show=&quot;always&quot;) Figure 10. Interactive plot of average precipitation by day of year at Swamp Angel study plot. #Write a function to create yearly plots for precip by day of year with ggplot precip_plotter2 &lt;- function(df, year) { precip_daily4 &lt;- df %&gt;% group_by(month, day, year, site) %&gt;% summarize(mean_precip = mean(precip, na.rm = T)) %&gt;% mutate(date = as.Date(paste(year, month, day, sep = &quot;/&quot;))) %&gt;% mutate(yday = yday(date)) %&gt;% pivot_wider(names_from = site, values_from = mean_precip) %&gt;% select(-SBSP) %&gt;% filter(year == i) print( ggplot(precip_daily4, aes(x = yday, y = SASP)) + geom_point(alpha=0.5) + theme_few() + labs( title = i, x = &#39;Day of Year&#39;, y = expression(&#39;Average Precipitation&#39; ~ (&#39;kg&#39; * m ^ 2 * &#39; per day&#39;))) + scale_x_continuous(breaks = c(1, 90, 180, 270, 360)) ) } #Use for loop to plot years 2005 to 2010 yrs = c(2005:2010) for (i in yrs){ precip_plotter2(forcing_data_full,year) } Figures 11-16. Yearly plots (2005-2010) of precipitation by day of year at the Swamp Angel study plot. 3.6 References The Center for Snow and Avalanche Studies. (2021). Archival Data From Senator Beck Study Basin. https://snowstudies.org/archived-data/ Data Retrieval R Packages Wickham, H. (2021). rvest: Easily Harvest (Scrape) Web Pages. R package version 1.0.2. https://CRAN.R-project.org/package=rvest Wickham, H. and Bryan, J. (2019). readxl: Read Excel Files. R package version 1.3.1. https://CRAN.R-project.org/package=readxl "],["geospatial-analysis.html", "Chapter 4 Geospatial Analysis 4.1 Introduction 4.2 Methods 4.3 Results 4.4 References", " Chapter 4 Geospatial Analysis 4.1 Introduction This project served as an introduction to spatial analysis in R and consisted of two parts. In part one, we utilized data from the LAGOS-NE Locus module to investigate the spatial distribution and size of lakes in three midwestern US states: Illinois, Iowa, and Minnesota. LAGOS-NE is a geospatial and temporal database of lake ecological context and water quality for 17 states in the midwestern and northeastern United States (Soranno and Cheruvelil 2017). Project objectives: Use mapview package to create interactive maps Utilize sf package to work with geospatial vector data Assess the distribution of lake size across states 4.2 Methods Data Acquisition We utilized the LAGOSNE R package to retrieve LAGOS-NE data. #Download LAGOS data # LAGOSNE::lagosne_get(dest_folder = LAGOSNE:::lagos_path()) #Load in LAGOS data lagos &lt;- lagosne_load() #Parse out lake centroid information lake_centers &lt;- lagos$locus # load(&#39;lake_centers.Rdata&#39;) Data Processing #Create spatial object for lakes spatial_lakes &lt;- st_as_sf(lake_centers,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) %&gt;% st_transform(2163) #Subset number of lakes for plotting subset_spatial &lt;- spatial_lakes %&gt;% slice(1:100) subset_baser &lt;- spatial_lakes[1:100,] #Dynamic mapviewer for LAGOS lake subset mapview(subset_spatial, layer.name=&quot;LAGOS lake subset&quot;) Figure 1. A subset of lakes within the LAGOS dataset for an introduction to dynamic mapping with the mapview R package. #Create states variable states &lt;- us_states() #Select only Minnesota from states data minnesota &lt;- states %&gt;% filter(name == &#39;Minnesota&#39;) %&gt;% st_transform(2163) #Subset lakes based on spatial position minnesota_lakes &lt;- spatial_lakes[minnesota,] 4.3 Results #Plot the first 1000 Minnesota lakes #Color by lake area in hectares minnesota_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(.,zcol = &#39;lake_area_ha&#39;, at=c(0,500,1500,3000,7500,15000,30000,65000,125000),cex=&#39;lake_area_ha&#39;,layer.name=&#39;Lake area (ha)&#39;)+ mapview(minnesota,layer.name=&quot;Minnesota&quot;, alpha.regions=0.35, col.regions=&quot;#fcf87f&quot;) Figure 2. Interactive map of Minnesota Lakes, colored by lake area in hectares. #Create interactive plot of Iowa and Illinois lakes #Color by lake area in hectares istate_lakes %&gt;% arrange(-lake_area_ha) %&gt;% slice(1:1000) %&gt;% mapview(., zcol = &#39;lake_area_ha&#39;, at=c(0,100,250,500,1000,2500,5000,10000), cex=&#39;lake_area_ha&#39;, layer.name=&#39;Lake area (ha)&#39;)+ mapview(i_states,zcol=&#39;name&#39;, alpha.regions=0.35, col.regions=c(&quot;#DAA520&quot;,&quot;#9F2B68&quot;), layer.name=F) Figure 3. Interactive map of Iowa and Illinois lakes, colored by lake area in hectares. Figure 4. Distribution of Minnesota lake size in hectares. Figure 5. Distribution of Iowa lake size in hectares. Figure 6. Distribution of Illinois lake size in hectares. In our analysis of the spatial distribution and size of lakes in Minnesota, Iowa, and Illinois, we found Minnesota exceeded the other two states both in the number of sites included in the LAGOS dataset and the size of lakes recorded in each state. There are 16446 sites in the LAGOS dataset for Illinois and Iowa combined. Meanwhile, there are 29038 Minnesota sites, exceeding the number of sites in Illinois/Iowa by 12572 sites. Furthermore, Minnesota lake size was generally greater than Iowa and Illinois lake size. Though, the distributions of lake size for all states are positively skewed. Additional data sources Additional useful sources for assessing reservoir and lake size: *The Global Lake area, Climate, and Population (GLCP) dataset is comprised of lake surface area data (from the datasets listed below), as well as temperature, precipitation, and population data (Meyer et al. 2020). *The HydroLAKES dataset combines information from multiple lake datasets, including NASA SRTM, Water Body Data, and the Global Lakes and Wetlands Database (Meyer et al. 2020). This dataset consists of shapefiles with attributes such as lake surface area, total volume, average depth, geographic coordinates of pour points, and more (Meyer et al. 2020). *The Global Surface Water Dataset, derived from LANDSAT imagery and hosted by the Joint Research Centre (JRC), provides information regarding surface water area for lakes, as well as rivers, streams, and wetlands (Meyer et al. 2020). A subset of this data based upon yearly water classification history is available via Google Earth Engine (Meyer et al. 2020). *Also, the Central Midwest Water Science Center is another resource, for Iowa and Illinois lake data specifically. 4.4 References Meyer, MF., Labou, SG., Cramer, AN., Brousil, MR., and Luff, BT. (2020). The global lake area, climate, and population dataset. Scientific Data, 7(1), 112. https://doi.org/10.1038/s41597-020-0517-4 Soranno, P. and Cheruvelil, K. (2017). LAGOS-NE-LIMNO v1.087.1: A module for LAGOS-NE, a multi-scaled geospatial and temporal database of lake ecological context and water quality for thousands of U.S. Lakes: 1925-2013 ver2. Environmental Data Initiative. https://doi.org/10.6073/pasta/56cc5f1f753d48edfea170a5401dd6df Data Retrieval R Packages Stachelek J., Oliver S., and Masrour, F. (2019). LAGOSNE: Interface to the Lake Multi-scaled Geospatial and Temporal Database. R package version 2.0.2. https://cran.r-project.org/package=LAGOSNE "],["geospatial-analysis-water-quality.html", "Chapter 5 Geospatial Analysis: Water Quality 5.1 Introduction 5.2 Methods 5.3 Results 5.4 References", " Chapter 5 Geospatial Analysis: Water Quality 5.1 Introduction This chapter describes part two of our geospatial analysis project. For part two, we expanded upon our intial analysis and used in-situ water quality data from the LAGOS-NE Limno module. We focused on two water quality metrics: chlorophyll a concentrations and secchi disk depth. Project objectives: Determine which states have the most water quality data for metrics of interest Assess the correlation between chlorophyll a concentrations and secchi disk depths Evaluate if there is a spatial pattern for secchi disk depth in lakes with observations exceeding 200 5.2 Methods Similar to Geospatial Analysis part one, we retrieved lake water quality data using the LAGOSNE R package. Data Acquisition #Load LAGOS water quality data nutr &lt;- lagos$epi_nutr #Select clarity variables only from LAGOS water quality data clarity_only &lt;- nutr %&gt;% select(lagoslakeid,sampledate,chla,doc,secchi) %&gt;% mutate(sampledate = as.character(sampledate) %&gt;% ymd(.)) Data Processing #Filter data to remove NA values from variables of interest: Chla and Secchi Disk Depth chla_secchi &lt;- clarity_only %&gt;% filter(!is.na(chla), !is.na(secchi)) #Include only lakes with at least 200 observations for Chla and Secchi Disk Depth chla_secchi_200 &lt;- chla_secchi %&gt;% group_by(lagoslakeid) %&gt;% mutate(count = n()) %&gt;% filter(count &gt; 200) #Join chla/secchi data to spatial lake data with observations &gt; 200 spatial_200 &lt;- inner_join(spatial_lakes,chla_secchi_200 %&gt;% distinct(lagoslakeid,.keep_all=T), by=&#39;lagoslakeid&#39;) #Calculate mean chla and secchi by lake mean_values_200 &lt;- chla_secchi_200 %&gt;% #Group by lake id group_by(lagoslakeid) %&gt;% #Calculate mean chla and secchi per lake id summarize(mean_chl = mean(chla,na.rm=T), mean_secchi=mean(secchi,na.rm=T)) %&gt;% #Filter NAs filter(!is.na(mean_chl), !is.na(mean_secchi)) %&gt;% #Calculate log base 10 of the mean_chl mutate(log10_mean_chl = log10(mean_chl)) #Join mean chla/secchi data to spatial lake data mean_spatial &lt;- inner_join(spatial_lakes,mean_values_200, by=&#39;lagoslakeid&#39;) 5.3 Results Spatial Distribution: LAGOS-NE Locus and Limno Data #Create dataframe with total number of counts per site from LAGOS data site_counts &lt;- chla_secchi %&gt;% group_by(lagoslakeid) %&gt;% summarize( mean_chla= mean(chla, na.rm=T), mean_secchi=mean(secchi,na.rm=T), count = n()) #Add geographic information to site counts data (points) geo_counts &lt;- inner_join(site_counts,lake_centers, by= &#39;lagoslakeid&#39;)%&gt;% select(lagoslakeid,nhd_long,nhd_lat, count) #Create spatial object for site counts data spatial_counts &lt;- st_as_sf(geo_counts,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) mapview(spatial_counts, cex=&quot;count&quot;, zcol=&quot;count&quot;, layer.name=&quot;Observations Per Lake&quot;, legend.opacity=0.05) Figure 1. Map depicting the number of observations per lake by circle size. The lakes with the highest number of observations are as follows: Lake Champlain, Vermont (n = 1466); Oneida Lake, New York (n = 653); Allequash Lake, Wisconsin (n = 503); Lake of the Ozarks, Missouri (n = 502); and Big Muskellunge Lake; Wisconsin (n = 497). #Use a spatial join to combine point data and us_boundaries data #Parse out state boundaries from us_boundaries data states &lt;- us_states() #Use spatial join to overlay point data and state boundaries overlay &lt;- st_join(spatial_counts,states) #Group by state and sum number of observations by state summed_overlay &lt;- overlay %&gt;% group_by(state_name) %&gt;% summarize(sum_count = sum(count)) %&gt;% arrange(desc(sum_count)) #Join state boundary data to summed counts of water quality observations summed_states &lt;- st_join(x = states, y = summed_overlay, left = TRUE)%&gt;% select(state_name.y,sum_count,geometry)%&gt;% filter(!is.na(sum_count)) #Visualize number of observations within each state mapview(summed_states,zcol=&quot;sum_count&quot;, layer.name=&#39;Observations Per State&#39;,alpha=0.2, legend.opacity=0.05) Figure 2. Interactive map visualizing the total number of observations within each state. The top five states with the most data include: Minnesota, Wisconsin, New York, Rhode Island, Missouri, and Vermont. Water Clarity: Chlorophyll A and Secchi Disk Depth Figure 3. Chlorophyll a and secchi disk depth measurements across lakes (number of observations exceeding 200). I used a test of correlation to assess the relationship between chlorophyll a concentrations and secchi disk depths in lakes with greater than 200 observations of each variable. There is a negative correlation between secchi disk depth and chlorophyll a levels, where shallower secchi disk depths are associated with higher chlorophyll a levels (p-value = 2.2e-16). High cholorphyll a concentrations are associated with high density(s) of photosynthetic organisms, such as algae. Meanwhile, secchi disks are used to assess water turbidity, where the depth of disk disappearance indicates the transparency of the water (Fuller and Minnerick 2007). Where algae abundance is high, the depth where light can penetrate a water body diminishes; thus, secchi disk depth decreases (Fuller and Minnerick 2007). Figure 4. Map visualizing (log transformed) average chlorophyll a concentrations across lakes, where chlorophyll a observations exceed 200 within the LAGOS Limno dataset (n &gt; 200). #Filter by 200 or more observations #Calculate the mean secchi depth by lake secchi200 &lt;- chla_secchi %&gt;% group_by(lagoslakeid) %&gt;% mutate(count = n()) %&gt;% filter(count &gt; 200) %&gt;% summarize(mean_secchi = mean(secchi)) #Add geographic information, joining by lagoslakeid secchi200_locus &lt;- inner_join(secchi200, lake_centers, by=&#39;lagoslakeid&#39;) %&gt;% select(lagoslakeid, nhd_long, nhd_lat, mean_secchi) #Create a spatial object with lagoslakeid and mean secchi data spatial_secchi200 &lt;- st_as_sf(secchi200_locus,coords=c(&#39;nhd_long&#39;,&#39;nhd_lat&#39;), crs=4326) #Visualize secchi data within interactive plot/map mapview(spatial_secchi200, zcol=&#39;mean_secchi&#39;, layer.name=&#39;Secchi Disk Depth&#39;) Figure 5. Map visualizing average secchi disk depths in meters across lakes, where secchi disk depth observations exceed 200 within the LAGOS Limno dataset (n &gt; 200). I did not find an exceptionally strong spatial pattern in secchi disk depth in lakes with at least 200 observations, given the number of lakes with observations exceeding 200 is small. However, the patch of lakes near/surrounding the Minneapolis-Saint Paul sprawl in Minnesota have broadly shallower secchi disk depths. Meanwhile, lakes in more remote areas in northern Wisconsin and near the Adirondacks in New York have generally deeper secchi disk depths. Despite a relatively weak spatial pattern, it is probable lakes within more remote areas have generally deeper secchi depths and urban areas shallower depths. 5.4 References Fuller, LM. and Minnerick, RJ. (2007). Predicting Water Quality by Relating Secchi-Disk Transparency and Chlorophyll a Measurements to Landsat Satellite Imagery for Michigan Inland Lakes, 20012006. USGS, August 2007, 14. http://pubs.usgs.gov/fs/2007/3022/pdf/FS2007-3022.pdf Soranno, P. and Cheruvelil, K. (2017). LAGOS-NE-LIMNO v1.087.1: A module for LAGOS-NE, a multi-scaled geospatial and temporal database of lake ecological context and water quality for thousands of U.S. Lakes: 1925-2013 ver2. Environmental Data Initiative. https://doi.org/10.6073/pasta/56cc5f1f753d48edfea170a5401dd6df Data Retrieval R Packages Stachelek J., Oliver S., and Masrour, F. (2019). LAGOSNE: Interface to the Lake Multi-scaled Geospatial and Temporal Database. R package version 2.0.2. https://cran.r-project.org/package=LAGOSNE "],["regression-models.html", "Chapter 6 Regression Models 6.1 Introduction 6.2 Methods 6.3 Data Acquisition: PRISM Temperature Data 6.4 Analyses: Temperature trends in Winneshiek County, Iowa 6.5 Data Acquisition: NASS Crop Yield Data 6.6 Analyses and Results: Corn Yield in Winneshiek County, Iowa 6.7 Analyses and Results: Corn Yield in all Iowa Counties 6.8 Analyses and Results: Soy Yield in all Iowa Counties 6.9 References", " Chapter 6 Regression Models 6.1 Introduction In this project, we explored regression models for analyzing temperature and crop yield in Iowa, USA. We utilized PRISM temperature data and USDA National Agricultural Statistics Service (NASS) yield data for corn and soybean crops. We first explored temperature trends in Winneshiek County, Iowa for an introduction to regression models. In the second portion of the project, we analyzed corn yield specifically within Winneshiek County and across all Iowa counties. We also investigated soybean yields across all Iowa counties. We used regression analyses to address the following questions: Is there a significant time trend for corn yield in Winneshiek county? Is there evidence for slowing corn yield growth over time in Winneshiek county? What is the relationship between average summer maximum temperature and corn yields in Winneshiek county? What is the relationship between average summer maximum temperature and corn yields across all Iowa counties for a single year? What is the impact of adding particular covariates, such as county code, to a regression model for corn yield in Iowa? Is there a spatial pattern in corn yield across all Iowa counties over time? What is the relationship between average summer maximum temperature and soy yields across all Iowa counties for a single year? 6.2 Methods 6.3 Data Acquisition: PRISM Temperature Data Dr. Nathan Mueller provided previously acquired PRISM data for class use. #Load PRISM daily max temperature #Dimensions: counties x days x years prism &lt;- readMat(&quot;dataRegression/prismiowa.mat&quot;) Data Cleaning #Assign dimension names to tmax matrix dimnames(prism$tmaxdaily.iowa) &lt;- list(prism$COUNTYFP, 1:366, prism$years) #Convert 3d matrix into a data frame tmaxdf &lt;- as.data.frame.table(prism$tmaxdaily.iowa) #Relabel columns within data frame colnames(tmaxdf) &lt;- c(&quot;countyfp&quot;,&quot;doy&quot;,&quot;year&quot;,&quot;tmax&quot;) tmaxdf &lt;- tibble(tmaxdf) 6.4 Analyses: Temperature trends in Winneshiek County, Iowa Summer temperature trends #Save doy and year as numeric variables tmaxdf$doy &lt;- as.numeric(tmaxdf$doy) tmaxdf$year &lt;- as.numeric(as.character(tmaxdf$year)) #Create data frame for Winneshiek County summer mean max temp winnesummer &lt;- tmaxdf %&gt;% filter(countyfp==191 &amp; doy &gt;= 152 &amp; doy &lt;= 243) %&gt;% group_by(year) %&gt;% summarize(meantmax = mean(tmax)) #Fit linear model for Winneshiek County mean summer max temp by year lm_summertmax &lt;- lm(meantmax ~ year, winnesummer) tidy(summary(lm_summertmax)) Winter temperatures trends #Fit linear model for Winneshiek County mean winter max temp by year lm_wintertmax &lt;- lm(meantmax ~ year, winnewinter) tidy(summary(lm_wintertmax)) Quadratic time trend - Winneshiek County, Iowa temperature #Fit lm for quadratic time trend lm_wintertmaxquad &lt;- lm(meantmax ~ year + yearsq, winnewinter) winnewinter$fitted &lt;- lm_wintertmaxquad$fitted.values tidy(summary(lm_wintertmaxquad)) 6.5 Data Acquisition: NASS Crop Yield Data We retrieved NASS data using the rnassqs package in R. 6.6 Analyses and Results: Corn Yield in Winneshiek County, Iowa 6.6.1 Question A: Is there a signicant time trend for corn yield? Linear time trend analysis Simple Linear Regression - Yield by Covariate: Year #Extract Winneshiek County corn yields winne_yields &lt;- cornyields %&gt;% filter(county_ansi == 191) # Fit a model for yield as the response (y) and year as predictor (x) winne_timeLM &lt;- lm(yield ~ year, data = winne_yields) tidy(summary(winne_timeLM)) #Add fitted values from linear model to data frame winne_yields$fitted_l &lt;- winne_timeLM$fitted.values With a p-value of 1.77e-13 and less than \\(\\alpha\\) = 0.05, we reject the null hypothesis \\(H_0:\\beta_1\\) = 0. We have enough evidence to suggest there is a significant time trend and a positive linear relationship between year and yield. There is an estimated 2.457 bu/acre increase in corn yield with each increasing year. 75.51% of the variation in corn yield is explained by the regression on year. 6.6.2 Question B: Is there evidence for slowing yield growth? Quadratic time trend analysis Quadratic Regression - Yield by Covariates: Year,Year2 # Create column for year^2 winne_yields$yearsq &lt;- winne_yields$year^2 #Fit quadratic time trend with yield(y) and year and year^2 as covariates(x) quad_timeLM &lt;- lm(yield~year + yearsq, data = winne_yields) tidy(summary(quad_timeLM)) #Add fitted values from the quad model to data frame winne_yields$fitted_q &lt;- quad_timeLM$fitted.values There is not strong evidence to suggest there is slowing yield growth over time. The p-value associated with the overall quadratic regression on year and year2 is 2.311e-12 and less than \\(\\alpha\\) = 0.5, suggesting there is a relationship between yield and one of the covariates in the model. However, the p-value(s) for each variable independently, year (p-value = 0.745) and year2 (p-value = 0.723), are greater than \\(\\alpha\\) = 0.5. Given the results of the regression on year alone suggest a linear relationship between yield and year, the linear year term is likely contributing to overall model significance. Thus, this implies the quadratic year2 term is not applicable. Furthermore, the R-squared values between the linear model and quadratic model with regressor(s) year and/or year2 are comparable at 75.51% or 75.59%, respectively. However, with reference to the adjusted R-squared value, 74.31% of the variation in yield is explained by the quadratic regression on year (and year2); this is slightly less the variation in yield explained by the regression on year alone (75.51%). These pieces of information suggest the higher order model, with adding in year2, does not provide greater predictive ability. 6.6.3 Question C: What is the relationship between average summer maximum temperature and corn yields? Time series analysis within Winneshiek County, Iowa SLR - Yield by Covariate: Average Summer Maximum Temperature #Add average summer Tmax to winne_yield data winne_summer_yield &lt;- left_join(winne_yields,winnesummer, by = &quot;year&quot;)%&gt;% filter(!is.na(meantmax)) #Fit a model for yield(y) and average summer maximum temperature(x) alone winne_tempLM &lt;- lm(yield~meantmax, data=winne_summer_yield) tidy(summary(winne_tempLM)) #Add fitted values to data frame winne_summer_yield$fitted_2 &lt;- winne_tempLM$fitted.values With a p-value of 0.2902 and greater than \\(\\alpha\\) = 0.05, we fail to reject the null hypothesis \\(H_0:\\beta_1\\) = 0. We do not have sufficient evidence to suggest there is a linear relationship between average summer maximum temperature and yield. 3.1% of the variation in corn yield is explained by the regression on average summer maximum temperature alone. Multiple Regression - Yield by Covariates: Average Summer Maximum Temperature, Year #Add summer Tmax^2 to winne_summer_yield winne_summer_yield$meantmaxsq &lt;- winne_summer_yield$meantmax^2 #Fit a model for yield(y) with covariates(x): average summer max temp and year temp_yearLM &lt;- lm(yield~meantmax + year, data=winne_summer_yield) tidy(summary(temp_yearLM)) #Add fitted values from model to data frame winne_summer_yield$fitted_2a &lt;- temp_yearLM$fitted.values With a p-value of 1.01e-11 and less than \\(\\alpha\\) = 0.05, we reject the null hypothesis \\(H_0:\\beta_1 = \\beta_2\\) = 0. We have evidence of a positive linear relationship between year and yield, when average summer max temp is held constant. There is an estimated 2.514 bu/acre increase in corn yield with each increasing year, holding all else constant. 73.18% (Adjusted R-squared) of the variation in corn yield is explained by the regression on average summer maximum temperature and year. Thus, adding year to the original model analyzing yield by average summer maximum temperature improves model predictive ability. Quadratic Regression - Yield by Covariates: Average Summer Max Temperature, Max Temperature2 #Fit a model for yield with covariates: average summer max temp and max temp^2 quad_tempLM &lt;- lm(yield~meantmax + meantmaxsq, data=winne_summer_yield) tidy(summary(quad_tempLM)) #Add fitted values from model to data frame winne_summer_yield$fitted_2b &lt;- quad_tempLM$fitted.values In prior analyses, we found there was not sufficient evidence of a linear relationship between yield and average summer max temp (p-value = 0.2902, R2 = 3.1%). However, in adding the quadratic term to the model (Tmax2), 19.84% (Adjusted R-squared) of the variation in corn yield is explained by the regression on average summer max temp and average summer max temp squared. The quadratic model, therefore, describes greater variability in yield above and beyond the regression on average summer max temp alone. Furthermore, the p-value from the F-statistic for the quadratic model overall is 0.007887 and less than \\(\\alpha\\) = 0.05, whereas the p-value from the linear model F-statistic is 0.2902. This suggests the higher order model serves as a better predictive model. When looking at the plot of yield by average summer maximum temperature, we can see there is high variability. However, the curvature of the line for the fitted quadratic model suggests corn yield increases with temperature until reaching an optimal temperature for plant growth, then declines with temperatures exceeding the optimal temperature. 6.7 Analyses and Results: Corn Yield in all Iowa Counties 6.7.1 Question D: Is there a relationship between temperature and yield across all counties in 2018? Cross-section analysis across all Iowa Counties in 2018 SLR - Yield by Covariate: Average Summer Max Temperature #Fit a linear model with yield (y) and average summer Tmax (x) yield_2018LM &lt;- lm(yield~meantmax, data=countytmax2018) tidy(summary(yield_2018LM)) #Add fitted values from model to data frame countytmax2018$fitted_l &lt;-yield_2018LM$fitted.values #Plot yield(y) by average summer maximum temperature (x) # ggplot(aes(x = meantmax, y = yield), data = countytmax2018) + # geom_point(shape = 1) + # geom_line(mapping = aes(x=meantmax, y=fitted_l))+ # theme_few() + # labs(x = expression(&quot;Average Summer Maximum Temperature (&quot;*degree*C*&quot;)&quot;), y = &quot;Yield (Bu/Acre)&quot;, title = &quot;Corn Yields across Iowa Counties in 2018&quot;) 2.7% of the variation in corn yields is explained by a simple linear regression on average summer max temp across all Iowa counties in 2018. With a p-value of 0.0631 and greater than \\(\\alpha\\) = 0.05, we fail to reject the null hypothesis \\(H_0:\\beta_1\\) = 0. We do not have sufficient evidence to suggest there is a linear relationship between yield and average summer max temp across all Iowa counties in 2018. QR - Yield by Covariates: Average Summer Max Temperature, Max Temperature2 #Add Tmax^2 to data frame countytmax2018$meantmaxsq &lt;- countytmax2018$meantmax^2 #Fit a quadratic model with yield (y) and average summer Tmax and Tmax^2 yield_2018_QR&lt;- lm(yield~meantmax + meantmaxsq, data=countytmax2018) tidy(summary(yield_2018_QR)) #Add fitted values from model to data frame countytmax2018$fitted_q &lt;-yield_2018_QR$fitted.values #Plot yield(y) by average summer maximum temperature (x) # ggplot(aes(x = meantmax, y = yield), data = countytmax2018) + # geom_point(shape = 1) + # geom_line(mapping = aes(x=meantmax, y=fitted_q))+ # theme_few() + # labs(x = expression(&quot;Average Summer Maximum Temperature (&quot;*degree*C*&quot;)&quot;), y = &quot;Yield (Bu/Acre)&quot;, title = &quot;Corn Yields across Iowa Counties in 2018&quot;) While we did not find enough evidence of a linear relationship between average summer max temp and yield across all Iowa counties in 2018 (p-value 0.0631 &gt; \\(\\alpha\\)), there is evidence of an overall significant quadratic temperature trend (p-value = 0.001736). 11.24% of the variation in corn yield is explained by the quadratic regression on mean max temperature and mean max temperature squared, across all Iowa counties in 2018. 6.7.2 Question E: What is the impact of certain covariates to the corn yield regression model? #Create data frame for yearly summer tmax across counties yearly_co_temp &lt;- tmaxdf %&gt;% group_by(countyfp,year)%&gt;% filter(doy &gt;= 152 &amp; doy &lt;= 243) %&gt;% summarize(meantmax = mean(tmax)) #Combine county and temperature data co_yearly_join &lt;- left_join(yearly_co_temp, corn_yields, by= c(&#39;countyfp&#39;,&#39;year&#39;))%&gt;% filter(!is.na(yield)) #Add Tmax^2 to data frame co_yearly_join$meantmaxsq &lt;- co_yearly_join$meantmax^2 SLR - Yield by Covariate: Year #Fit SLR with yield as response (y) and covariate year (x) SLR_LM &lt;- lm(yield~ year, data = co_yearly_join) tidy(summary(SLR_LM)) #Add fitted values to data frame co_yearly_join$fit_SLR &lt;- SLR_LM$fitted.values Quadratic Regression - Yield by Covariates: Average Summer Maximum Temperature, Max Temperature2 #Fit quadratic model for mean max tempearture (x) QR_LM &lt;- lm(yield~ meantmax+ meantmaxsq, data = co_yearly_join) tidy(summary(QR_LM)) #Add fitted values to data frame co_yearly_join$fit_QR &lt;- QR_LM$fitted.values Multiple Regression - Yield by Covariates: Average Summer Maximum Temperature, Max Temperature2, Year # Fit multiple regression yield by Average Summer Maximum Temperature, Max Temperature^2, Year MR_LM &lt;- lm(yield~ meantmax+ meantmaxsq+ year, data = co_yearly_join) tidy(summary(MR_LM)) #Add fitted values to data frame co_yearly_join$fit_MR &lt;- MR_LM$fitted.values Panel Regression - Yield by Covariates: Average Summer Maximum Temperature, Max Temperature2, Year, County code #Fit a panel regression panelLM &lt;- lm(yield~ meantmax+ meantmaxsq+ year+countyfp, data = co_yearly_join) tidy(summary(panelLM)) #Add fitted values to data frame co_yearly_join$fit_panel &lt;- panelLM$fitted.values In order to assess the applicability of the panel regression model (later referred to as model D), I ran the following models for comparison: a) a simple linear regression with yield by year, b) a quadratic regression with yield by average summer max temp and average summer max temp2, and c) a multiple regression with yield by year, average summer max temp, and max temp2. For model A, 52.41% of the variability in corn yield is explained by the regression on year. For model B, 19.43% (adjusted R2) of the variation in corn yield is explained by the quadratic regression on average summer max temperature. For model C, 65.65% (adjusted R2) of the variation in yield is explained by the regression on the model covariates. Finally, for model D, 71.29% (adjusted R2) of the variation in corn yield is explained by all covariates in the model including county code. The following list includes the p-values associated with the coefficients for average summer max temperature and average summer max temp2, while holding all else constant, in the models: Model B: Average Max Temp (p-value = &lt;2e-16), Max Temp2 (p-value = &lt;2e-16) Model C: Average Max Temp (p-value = &lt;2e-16), Max Temp2 (p-value = &lt;2e-16) Model D: Average Max Temp (p-value = &lt;2e-16), Max Temp2 (p-value = &lt;2e-16) As evidenced by the information above, the significance of the temperature coefficients remained consistent across models. In the case of the panel regression, when incorporating county ID into the model, it could be that the coefficients for temperature remained consistent given counties within Iowa may experience broadly similar weather (and thus temperature regimes). 6.7.3 Question F: Is there a spatial pattern in corn yield across all Iowa counties over time? #Simplify data by only mapping yield data from one year cornyield_2017 &lt;- corn_yields %&gt;% filter(year==2017) %&gt;% dplyr::select(county_name, yield, countyfp) #Combine yield and spatial county data co_yields &lt;- merge(counties, cornyield_2017, by.x = &quot;name&quot;, by.y = &quot;county_name&quot;, all.x=TRUE) #Map yield by county mapview(co_yields, zcol= &#39;yield&#39;, layer.name=&quot;2017 Corn Yield - Bu per Acre&quot;) Viewing the map of 2017 corn yields across Iowa counties (especially in tandem with the maps below), there appears to be a spatial pattern where corn yields are generally lowest in southern Iowa counties. Furthermore, specifically for the 2017 year, there appears to be higher corn yields in the eastern portion of the state versus the western side. #Create data frame with corn yield from last 9 years cornyield_time &lt;- corn_yields %&gt;% filter (year %in% c(1985,1990,1995,2000,2005,2010,2015,2020,2021)) %&gt;% dplyr::select(year, county_name, yield, countyfp) #Join to counties spatial data co_yields_time &lt;- merge(counties, cornyield_time, by.x=&quot;name&quot;, by.y=&quot;county_name&quot;, all.x=TRUE) #Use facet wrap by year to show corn yield over the last 9 years ggplot(na.omit(co_yields_time), aes(fill = yield)) + geom_sf() + scale_fill_viridis() + theme_few() + facet_wrap( ~ year, nrow = 3) + theme(axis.text.x = element_text( color = &quot;black&quot;, size = 7, angle = 30, vjust = .8, hjust = .8 )) + theme(axis.text.y = element_text(size = 8))+ labs(title=&quot;Iowa County Corn Yields Over Time&quot;, fill=&quot;Yield (Bu/Acre)&quot;)+ theme(legend.position = &quot;right&quot;, legend.key.width = unit(5, &quot;mm&quot;), legend.title=element_text(size=10)) The map(s) above shows corn yields across Iowa counties in 5 year intervals, in addition to the two most recent years with yield data. Broadly, this map is supportive of earlier findings from our analyses, where corn yields have generally increased with time. Spatially, the map indicates that south-central Iowa counties produce lower corn yields consistently over time, in comparison to other counties. 6.8 Analyses and Results: Soy Yield in all Iowa Counties 6.8.1 Question G: Is there a relationship between temperature and yield across all counties in 2018? Cross-section analysis of soy yields across all Iowa Counties in 2018 #Rename county_ansi to countyfp soy_yields &lt;- soyyields %&gt;% rename(&#39;countyfp&#39;= county_ansi) #Save countyfp as factor soy_yields$countyfp &lt;- as.factor(soy_yields$countyfp) #Filter for 2018 yields only county2018_soy &lt;- soy_yields %&gt;% filter(year==2018) #Combine average summer max temperature with county yield data for 2018 soytmax2018 &lt;- inner_join(county2018_soy, tmax2018, by=&#39;countyfp&#39;) SLR - Soy Yield by Covariate: Average Summer Max Temperature #Fit a linear model with soy yield (y) and average summer Tmax (x) soy_2018LM &lt;- lm(yield~meantmax, data=soytmax2018) summary(soy_2018LM) #Add fitted values from model to data frame soytmax2018$fitted_l &lt;-soy_2018LM$fitted.values With a p-value of 0.189 and greater than \\(\\alpha\\) = 0.05, we fail to reject the null hypothesis \\(H_0:\\beta_1\\) = 0. We do not have sufficient evidence to suggest there is a linear relationship between soy yield and average summer max temp across all Iowa counties in 2018. 0.78% of the variation in soy yields is explained by a simple linear regression on average summer max temp across all Iowa counties in 2018. QR - Soy Yield by Covariates: Average Summer Max Temperature, Max Temperature2 #Add Tmax^2 to data frame soytmax2018$meantmaxsq &lt;- soytmax2018$meantmax^2 #Fit a quadratic model with soy yield (y) and average summer Tmax and Tmax^2 soy_2018_QR&lt;- lm(yield~meantmax + meantmaxsq, data=soytmax2018) summary(soy_2018_QR) #Add fitted values from model to data frame soytmax2018$fitted_q &lt;-soy_2018_QR$fitted.values Similar to as observed with corn yields, soy yields in response to average summer max temp are better predicted by a quadratic regression. The p-value from the F-statistic for the linear model is 0.1893 and greater than \\(\\alpha\\) = 0.5, while the p-value for the overall quadratic model F-statistic is 0.00274 &lt; \\(\\alpha\\). 10.02% (Adjusted R2) of the variation in soy yield is explained by the quadratic regression on mean max temperature and mean max temperature2, across all Iowa counties in 2018. By adding the quadratic term to the model, the R2 value increased from 0.78% in the linear model to 10.02% with the quadratic regression. A similar temperature trend is present in soy yields as to corn yields. There is high variability in the data and the curvature of the fitted line for the quadratic model suggests increasing yield with increasing temperatures, until reaching a peak temperature for plant growth, then declining at temperatures exceeding optimal temperatures. One final note: overall, in bushels/acre units, corn yield was higher that soy yield in 2018. 6.9 References Data Retrieval R Packages Bengtsson, H. (2018). R.matlab: Read and Write MAT Files and Call MATLAB from Within R. R package version 3.6.2. https://CRAN.R-project.org/package=R.matlab Potter, NA. (2019). rnassqs: An R package to access agricultural data via the USDA National Agricultural Statistics Service (USDA-NASS) Quick Stats API. Journal of Open Source Software, 4(43), 1880. https://doi.org/10.21105/joss.01880 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
